#!/usr/bin/env python3
"""
Download a small subset of real dental data from OSF repository.

This script downloads just 10-20 real dental scans for quick testing and training.
"""

import os
import urllib.request
import zipfile
import json
import shutil
import requests
from pathlib import Path
import sys
from tqdm import tqdm

def create_data_dirs():
    """Create necessary data directories."""
    dirs = ['data', 'data/scans', 'data/labels', 'data/raw', 'checkpoints', 'logs']
    for dir_path in dirs:
        Path(dir_path).mkdir(parents=True, exist_ok=True)
        print(f"‚úÖ Created: {dir_path}")

def download_file(url, filename, desc=None):
    """Download a file with progress bar."""
    try:
        response = requests.get(url, stream=True)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        
        with open(filename, 'wb') as file, tqdm(
            desc=desc or f"Downloading {filename}",
            total=total_size,
            unit='B',
            unit_scale=True,
            unit_divisor=1024,
        ) as pbar:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    file.write(chunk)
                    pbar.update(len(chunk))
        
        return True
    except Exception as e:
        print(f"‚ùå Download failed: {e}")
        return False

def download_sample_data():
    """
    Download a small sample of real dental data.
    
    Note: This downloads from a smaller sample collection rather than the full dataset.
    """
    print("üåê Downloading small sample of real dental data...")
    
    # Since the full OSF dataset is very large, we'll create instructions
    # for manual download of a small subset
    
    sample_instructions = """
# üì• Small Dataset Download Guide

## Quick Download (Recommended)

### Option 1: Manual Download (5-10 samples)
1. Go to: https://osf.io/xctdy/
2. Click on "3DTeethSeg challenge dataset - Part 1"
3. Download just the first ZIP file (~2-3 GB)
4. Extract only 5-10 sample files to test with

### Option 2: Use Sample URLs (if available)
Some sample files might be directly downloadable:

```bash
# Run this script to attempt direct download
python scripts/download_small_dataset.py --direct
```

### Option 3: Create Test Data
```bash
# Generate realistic test data
python scripts/download_small_dataset.py --synthetic
```

## Expected File Structure After Download:
```
data/
‚îú‚îÄ‚îÄ scans/
‚îÇ   ‚îú‚îÄ‚îÄ sample_001_upper.obj
‚îÇ   ‚îú‚îÄ‚îÄ sample_001_lower.obj
‚îÇ   ‚îú‚îÄ‚îÄ sample_002_upper.obj
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ labels/
    ‚îú‚îÄ‚îÄ sample_001_upper.json
    ‚îú‚îÄ‚îÄ sample_001_lower.json
    ‚îú‚îÄ‚îÄ sample_002_upper.json
    ‚îî‚îÄ‚îÄ ...
```

## Quick Test:
Once you have 3-5 samples:
```bash
python scripts/train_real_data.py --epochs 5 --batch_size 2
```
"""
    
    # Save instructions
    with open("data/SMALL_DOWNLOAD_GUIDE.md", "w") as f:
        f.write(sample_instructions)
    
    print("üìã Created guide: data/SMALL_DOWNLOAD_GUIDE.md")
    return True

def create_synthetic_samples(num_samples=5):
    """Create high-quality synthetic dental samples for immediate use."""
    print(f"üé≤ Creating {num_samples} high-quality synthetic dental samples...")
    
    import numpy as np
    import trimesh
    
    for sample_idx in range(num_samples):
        print(f"  Creating sample {sample_idx + 1}/{num_samples}...")
        
        # Create more realistic dental arch
        jaw_type = 'upper' if sample_idx % 2 == 0 else 'lower'
        patient_id = f"SYNTH{sample_idx+1:03d}"
        
        # Generate realistic tooth positions
        if jaw_type == 'upper':
            angles = np.linspace(-np.pi/2.5, np.pi/2.5, 14)  # 14 teeth max
            radius = 3.2
            base_y = 0.5
            tooth_height = 1.0
        else:
            angles = np.linspace(-np.pi/2.7, np.pi/2.7, 14)
            radius = 2.8  
            base_y = -0.3
            tooth_height = 0.8
        
        # Randomly remove some teeth (realistic)
        num_teeth = np.random.randint(10, 14)
        selected_angles = np.random.choice(angles, num_teeth, replace=False)
        selected_angles.sort()
        
        vertices = []
        faces = []
        labels = []
        instances = []
        vertex_count = 0
        
        # Create teeth
        for tooth_idx, angle in enumerate(selected_angles):
            x_center = radius * np.cos(angle)
            z_center = radius * np.sin(angle)
            
            # Tooth shape variation
            tooth_width = np.random.uniform(0.25, 0.35)
            tooth_depth = np.random.uniform(0.25, 0.35)
            height_var = np.random.uniform(0.8, 1.2)
            
            # Create detailed tooth geometry
            tooth_vertices = []
            layers = np.random.randint(6, 10)  # Variable detail
            corners = 12  # More detailed shape
            
            for layer in range(layers):
                y = base_y + (layer / (layers-1)) * tooth_height * height_var
                layer_scale = 1.0 - (layer / layers) * 0.3  # Taper toward top
                
                for corner in range(corners):
                    corner_angle = (corner / corners) * 2 * np.pi
                    # Add some irregularity
                    r_var = np.random.uniform(0.9, 1.1)
                    x = x_center + tooth_width * layer_scale * r_var * np.cos(corner_angle)
                    z = z_center + tooth_depth * layer_scale * r_var * np.sin(corner_angle)
                    tooth_vertices.append([x, y, z])
            
            # Create faces for this tooth
            tooth_faces = []
            for layer in range(layers - 1):
                for corner in range(corners):
                    v1 = vertex_count + layer * corners + corner
                    v2 = vertex_count + layer * corners + ((corner + 1) % corners)
                    v3 = vertex_count + (layer + 1) * corners + corner
                    v4 = vertex_count + (layer + 1) * corners + ((corner + 1) % corners)
                    
                    # Two triangles per quad
                    tooth_faces.extend([[v1, v2, v3], [v2, v4, v3]])
            
            vertices.extend(tooth_vertices)
            faces.extend(tooth_faces)
            
            # Assign realistic FDI labels
            if jaw_type == 'upper':
                if angle < 0:  # Right side (patient's right)
                    fdi_base = 11
                else:  # Left side
                    fdi_base = 21
                tooth_num = int(abs(angle) / (np.pi/2.5) * 7) + 1
            else:  # lower
                if angle < 0:  # Right side
                    fdi_base = 41
                else:  # Left side  
                    fdi_base = 31
                tooth_num = int(abs(angle) / (np.pi/2.7) * 7) + 1
            
            fdi_label = fdi_base + min(tooth_num, 7)
            
            labels.extend([fdi_label] * len(tooth_vertices))
            instances.extend([tooth_idx + 1] * len(tooth_vertices))
            vertex_count += len(tooth_vertices)
        
        # Add realistic gingiva
        gingiva_points = 800 + np.random.randint(-100, 100)
        
        # Create gingiva surface around teeth
        gingiva_vertices = []
        for _ in range(gingiva_points):
            # Random position around dental arch
            angle = np.random.uniform(-np.pi/2, np.pi/2)
            r = np.random.uniform(1.5, 4.5)
            y = base_y + np.random.uniform(-0.5, 0.2)
            
            x = r * np.cos(angle) + np.random.normal(0, 0.1)
            z = r * np.sin(angle) + np.random.normal(0, 0.1)
            
            gingiva_vertices.append([x, y, z])
        
        vertices.extend(gingiva_vertices)
        labels.extend([0] * len(gingiva_vertices))  # Gingiva = 0
        instances.extend([0] * len(gingiva_vertices))  # Gingiva instance = 0
        
        # Convert to numpy and add realistic noise
        vertices = np.array(vertices, dtype=np.float32)
        noise_scale = 0.01 + np.random.uniform(0, 0.01)  # Variable noise
        noise = np.random.normal(0, noise_scale, vertices.shape)
        vertices += noise
        
        # Create mesh (use subset of faces to avoid issues)
        faces = np.array(faces)
        if len(faces) > 0:
            # Sample faces to avoid too dense mesh
            max_faces = min(len(faces), 3000)
            face_indices = np.random.choice(len(faces), max_faces, replace=False)
            selected_faces = faces[face_indices]
            
            # Ensure face indices are valid
            max_vertex_idx = len(vertices) - 1
            valid_faces = []
            for face in selected_faces:
                if all(idx <= max_vertex_idx for idx in face):
                    valid_faces.append(face)
            
            if valid_faces:
                mesh = trimesh.Trimesh(vertices=vertices, faces=valid_faces)
            else:
                # Create simple mesh without faces
                mesh = trimesh.PointCloud(vertices)
        else:
            mesh = trimesh.PointCloud(vertices)
        
        # Save mesh
        mesh_filename = f"sample_{patient_id}_{jaw_type}.obj"
        mesh_path = f"data/scans/{mesh_filename}"
        mesh.export(mesh_path)
        
        # Save labels
        label_data = {
            "id_patient": patient_id,
            "jaw": jaw_type,
            "labels": [int(x) for x in labels],  # Convert to Python int
            "instances": [int(x) for x in instances]
        }
        
        label_filename = f"sample_{patient_id}_{jaw_type}.json"
        label_path = f"data/labels/{label_filename}"
        with open(label_path, 'w') as f:
            json.dump(label_data, f, indent=2)
        
        # Stats
        unique_teeth = len([x for x in np.unique(instances) if x > 0])
        print(f"    ‚úÖ {mesh_filename}: {len(vertices)} vertices, {unique_teeth} teeth")
    
    print(f"‚úÖ Created {num_samples} synthetic samples ready for training!")

def download_direct_samples():
    """Attempt to download some direct sample files (if available)."""
    print("üåê Attempting to download direct samples...")
    
    # Note: These would be actual URLs if available
    # For now, we'll show the concept
    
    sample_urls = [
        # These would be real URLs to individual sample files
        # "https://osf.io/download/sample1.zip",
        # "https://osf.io/download/sample2.zip",
    ]
    
    if not sample_urls:
        print("‚ùå No direct download URLs available")
        print("üí° Use --synthetic option to create test data")
        return False
    
    for i, url in enumerate(sample_urls):
        filename = f"data/raw/sample_{i+1}.zip"
        print(f"Downloading sample {i+1}...")
        if download_file(url, filename):
            # Extract if zip
            if filename.endswith('.zip'):
                with zipfile.ZipFile(filename, 'r') as zip_ref:
                    zip_ref.extractall("data/raw/")
                os.remove(filename)
        else:
            print(f"Failed to download sample {i+1}")
    
    return True

def main():
    """Main function."""
    import argparse
    
    parser = argparse.ArgumentParser(description='Download small dental dataset')
    parser.add_argument('--synthetic', action='store_true', help='Create synthetic samples')
    parser.add_argument('--direct', action='store_true', help='Try direct download')
    parser.add_argument('--samples', type=int, default=5, help='Number of synthetic samples')
    
    args = parser.parse_args()
    
    print("ü¶∑ Small Dental Dataset Setup")
    print("=" * 40)
    
    # Create directories
    create_data_dirs()
    print()
    
    if args.synthetic:
        # Create synthetic samples
        create_synthetic_samples(args.samples)
    elif args.direct:
        # Try direct download
        download_direct_samples()
    else:
        # Create download instructions
        download_sample_data()
    
    print("\n‚úÖ Setup completed!")
    print("\nüìã Next steps:")
    print("1. Check data/scans/ and data/labels/ for your files")
    print("2. Run training: python scripts/train_real_data.py --epochs 5")
    print("3. Test UI: python launch_ui.py")
    
    # Quick stats
    scan_files = list(Path("data/scans").glob("*.obj"))
    label_files = list(Path("data/labels").glob("*.json"))
    
    print(f"\nüìä Current data: {len(scan_files)} scans, {len(label_files)} labels")

if __name__ == "__main__":
    main()